what's up guys this is Ronnie welcome back to our Channel Total technology Zone this is tutorial 126 and today's topic will be very advanced in this tutorial I'll be going to develop one Advanced rag on ayurvedic medicines using Lang chain okay so basically in this tutorial uh we'll be going to develop one rag which is uh basically on ayurva or aurvedic medicine where um you can ask any question related to um ayurvedic uh like medicine maybe you have some problem or someone has some problem and if they want to actually get the recommendation or write medicines they can actually get an help uh from the application and also if they want to know about some ayurvedic medicine components Etc even they will get those details okay so that will be very exciting okay so the prerequisite is actually little bit of web scraping knowledge the source code will be available in this tutorial uh sorry in this link uh in the gethub okay and now let's discuss about the tutorial flow so this is the first part where I'll be just going to develop the data for my Vector database okay okay so first uh first let's see first there will be on website so which website I'll be going to use I'll show you here so basically this an uh Indian website 1mg.com and if you go to this link so basically they have all the ayic components name based on their alphabet so basically we'll be going to web script from their website so guys before I actually start the tutorial I just want to um say something so my intention is not to uh like uh do any uh like commercial work with this data my intention is purely for knowledge purpose please don't misuse their data because um it's not um like good okay if you misuse that data so this is this is just an uh like um just a education purpose I'm helping you guys so that you guys can do the same thing okay so I'll be just going to scrape from all the letter uh alphabet from here and after that um uh let me actually open this thing so B basically extract all urls all urls will be there okay then we'll be going to use langin ASM chromium later to uh extract the HTML text from all URL and then we'll be going to use the HTML sub Transformer to convert the HTML text uh HTML into text and then we'll be going to inest the vector D so I think we'll be going to do up to this part here okay and in the second part we'll be just going to inest the data okay so let's start the tutorial let's minimize this thing and let's let's go here so if you see here this is something like this okay so what I'll do I'll just go into inspect I'll go into Network and then probably I can um I can actually refresh this page okay let's see okay so this is something here just hold on I just just want to know like how this things are coming okay uh from where to actually get those links for this all the things here okay okay let me clear this thing and let me click on a again I think uh that is here here here no here no here here here need to do little bit of web scoping so basically um okay let's refresh the page again okay this is actually AA we need a page where all the links will be available okay so that is what I'm looking for okay so let me okay so let's see one thing let's click on this a a button just hold on let's let's click on this a button okay so let's click on a button first yeah I think nothing is coming let's click on B button okay so I think this is the thing by alphabet okay so what I'll do let's copy this thing let's copy the payload headers whatever if I think this is a request URL let's copy this thing okay uh let's paste it here okay yeah I think that's it so if you see the alphabet a okay everything is coming like this okay so how many uh things are there like all everything will be here right okay all total 32 32 is SC so this is basically link we have to use this link uh for all the alphabets okay so this will be our URL Gen url. 5 so that is why I said a little bit of uh whb scaping knowledge will be required so this will be the URL okay remember so basically one URL will be this one okay URL one will be this one and URL will be this one okay right and basically okay just hold on let me I think I think I can change it I can change it to alphabet okay and I'm just going to give it a x string okay fine all done right so this is going to be our URL always this okay right okay okay so now let's see so import request then Jon then I okay then import input string okay let's create an alphabet list so uh Al alphabets so basically what I do I'll just going to write here alphabets okay let copy this thing alphabets equals to list of what list of of all alphabets how to get list of all alphabets basically from the F lower case Okay string do s lower case so basically this is going to give me all the list so I just want to show you so alphabet you see this is going to print all the alphabets here okay I think okay let's ignore this line for the let's execute so this is going to give me A to Z everything okay fine this is fine so I don't need this line again now what we'll be going to do we'll be going to write for alphabet in alphabets okay right so my URL is generated okay so let's print the URL and let's see whether I did any formation mistake or not so let's make it little bit bigger now okay so let's execute okay I think all the all the URLs are actually coming now let's go to here now if you see here this is just going to give you the name of the name of the medicine and a little bit uh description but the actual thing is actually available here in this link right for example let's say this is the medicine if I go here this is the main thing okay we need to scrape from this page so basically from this link we just need this URL basically from the schema so basically if I just go here so basically we need this URL for all the medicine so basically which is part of this schema right means first I'll call this link I will go to the schema inside the schema I'll just call this list and in the in the list in the list I need to actually get all the URL okay and their name basically okay so this name and URL okay so let's try to actually do that okay so first we'll be going to uh generate the URL and name for all the medicine okay right so now this is the URL okay so basically what will happen response equals to request. getet okay URL okay now let's see item items equals to response dot Jon okay okay so now this is my Json inside the Jon I need the data inside the data schema okay this is the schema so basically how to get this thing so see this is the main thing data and schema okay this this data then schema okay remember this thing okay Json then data and inside the data we need schema okay s c h e m right and now inside the schema we need this one right okay item list element okay okay so basically this is a list okay this is basically a list so then what will happen for item in items okay and within this list I need name and URL so basically if you see here I need this this the item this item so from every list uh is a dictionary every item is a dictionary inside the list I mean name and so B basically I need item name and item URL right everything is clear now okay so what we'll do we'll be just going to write a function so for that now what you have to do we have to open a file here with IO do so these things are required a little bit uh for generating the files uh url url dot you can write csb you can write txt it doesn't matter okay right and then okay P coding equals to UDF 8 as this one like this okay okay then P one WR equals to name okay uh items. name I think item do name item. name and item. URL right item. name is actually going to give me the name of the item and then URL okay so basically after that we're just going to put a comma right this and item do URL so guys remember the building a rag from production ready rack it is always useful that you should know a little bit of coding ORS it will will be difficult right yeah now some of you might say that uh we can do this thing using uh AI yeah definitely we can do this thing using AI but for that we are going to use some extra token but U also uh some some condition like for example in this website uh if I just go here if you see uh this links are actually like Java Script Ena so basically we need to like um create some Lex uh like thing okay yeah there are multiple like things are available in the market like which is uh where actually highlight this uh HTML part and this will click automatically to generate the link so that is also possible and for that maybe we need to pay a little bit of money but this is possible for example this if I go here uh this HTML tag has a specific name okay so if you see uh divide is chips okay so basically I want all the links from this button so it will automatically generate the link so here we have written um uh this many lines of code that will be easily replaced by that code okay so now my objective is actually to generate the URL so let's try to do it hopefully this will generate now okay so let's see so URL CSP created but it is now processing the thing hopefully in few minute everything will be generated yeah it's done now let's click on this thing now you see all links are here I think 200 or something will be coming okay coming all links are there right my generate URL part is over so basically from the this thing I generated this part now I'll be just going to do this thing html text from the URL using as as chromium loader okay let's try to do that okay okay so now we'll be going to do gen data py right so now let's clear okay now let's try to do the next part okay so this is a little bit of advanced code so that is why I have given name Advance coding Advance rag okay so first thing first it will be from where I'm writing I'm writing here actually okay so it will be writing from length chain community document loaders import sing chromium what is that s sync s syn chromium load okay right then probably we'll be just going to import chat prom template chat open a okay so from from I think it's import the beautiful soup as well uh Lin Community do document Transformers import beautiful soup Transformer okay now from from blank chain open import chat openi right and last but not least we'll be going to import PR template right so from okay okay so what is this from L chain do proms import prom import right so let's set up the llm first so chat open a and our model will be our model will be GPT I4 in this part I'll be just going to extract using uh uh llm okay so now let's set up a template okay template okay so for the given text extract every information is the information um related to uh name name means the AIC medicine okay don't extract extract only only anything related to okay done right now let's write the prompt prompt equals to prompt template okay and inside that I'll be just going to mention the template right so prom template do from template and I just the template here let's execute if there any error or something something yeah no error okay right now what we'll be just going to do we'll be just going to uh create a loader now okay here we'll just going to load the HTML so as sync promium loader and basically this is going to uh get the URLs okay so uh what I'll do uh I'll be just going to pass the URL one by one okay because um passing multiple URLs uh maybe a little bit uh uh what I say like little bit of uh uh difficult because I want to actually um get this thing from here as well okay so that is why so basically let's write this and there I'll be just going to pass the URL okay so now uh I'll be just going to write import IO right it's here right and from here actually the uh the task will start from here okay so first read the file here okay so how to read the file so let's generate URL and let's copy this part okay okay great okay data equals to f1. read okay and F1 do close Okay close so now what will happen here here so um URLs I just write l l equals to data do split sln right so now for line in line okay so URL will be line do split of comma the zero element so basically uh if I split this line with comma so Z will be the name and one will be the comma sorry so URL will be this one and the name will be the zero one right so name will be the 01 copy right okay and then what will happen you got the URL here so URL is actually getting ready then uh docs uh HTML loader uh equals to loader do load okay this loader in loader do load is actually going to load this thing okay then for this single thing we'll be just going to uh create a uh Beautiful s transform BS Transformer Transformer equals to full Su Transformer okay so now we'll be just going to create a transform document okay so let's create a transform document so basically uh let's see do transform trans4 M transform equals to uh vs Transformer dot transform documents so which document I want to transform I want to transform this uh I want to transform which document so basically this HTML uh L no no the HTML dots HTML dots HTML docs and which tag I want to uh extract the Deep tag so basically if you just just go here and click this thing see everything is actually comes under a deep tag okay so the Deep tag so yeah definitely this deep tags are not required but everything is actually deep tag if I just go I don't want to actually get any other tag so let's try to write text to extract so let's D okay so basically what will happen now now this is going to extract the Deep T okay right now let's see create a chain chain is equal to prompt and SL LM F okay and let's uh response equals to chain do invoke okay and there name equals to name and text equals to do Transformer okay so now after that I'll be just going to write print response okay and I want to actually stop it here I just want to do it for only one link and see whether everything is working fine then I want to do it for the remaining okay so it is just going to do it for the first uh link okay so let's execute so m will be replaced with this name and you uh text will be this text will be replaced by the transform text okay so let's execute so it started something is happening hopefully okay okay D is not defined okay so basically it should be within a double course okay okay no problem okay cool so this came okay this came nicely but uh I just want to actually uh write it response content okay so let's yep I think okay I think let's write X information short Buton use try to use okay so I'm saying that don't shorten the content let's see yeah okay I think this looks better yes yes okay fine so I think this is nice now what we'll do now we'll be actually going to create a document from this okay so for creating the document I believe uh we can actually convert that into a string and let's see okay how it is actually coming it is basically a string but let's see I know it's a string because print it is printing so obviously it's a string yeah okay so now basically um last time it gives uh information a little bit more here actually yeah let's try to actually build this document okay from the context from this context so what will happen now I'll just going to create with io. open I think I have IO yes i. open okay and rag text rag do this is my rag so rag do. txt okay and then W and then encoding equals to 58 okay as yeah iPhone I can use it because it is closed now what you'll do I just like this and now I don't want to actually do this thing here then I want to F1 WR okay like this okay and then just write like this and I don't want to now exit this thing at the end I want to exit once if all the lines are written then I want to exit okay right what is this but it is saying once the follow Loop is over I want to actually close it so yeah now this is fine now let's execute so basically what will happen this is actually going to create a document and it is going to use the open this is going to take a little bit of time let it continue okay so I want to actually write something here so that I will understand which is actually happening right now so basically I'm just want to write print name okay so that I will understand what is happening right now let's execute encoding c d i n g okay so done now let's wait so not a single one is started actually yeah basically it's working it it is processing basically so let's wait for some time yeah okay so it will be actually right w r i I don't know oh my God okay so let's try again uh I I did a mistake guys just hold on just hold on so name will be zero so sorry sorry let's execute okay so that is the mistake I did okay okay so okay it's working so this is the first one mhm mhm okay so this is actually taking time so let it run and we'll be just going to uh let finish let's say two three let's finish so it's working if you see the first one is done then the second one is done so like that way it is going to continue but uh I'll be not going to record this part because it is actually going to exhaust the video length actually unnecessarily so let it continue I'll be just going to uh catch up with all you all of you uh once the file is generated okay so till then uh just uh let me wait and let let it finish we'll see you soon all right so the data uh like generation is completed okay so this is the data so if you see it has 179k lines and it is basically script everything so now our next objective is actually um to develop a vector index from this data okay so let's gen index DOI okay so without wasting the time let's start working on that part okay so now in this part I'll be just going to use uh another uh framework llama index so basically it's a combination of langin and Lama index okay so it is very uh like exciting so first thing I'll be just going to use chroma DB for our Vector store so importa DV okay next uh we'll be going going to import from Lama index do core okay so what are the things we'll be going to import so first thing uh we'll be going to import simple directory reader okay simple simple directory read so we'll going to inut Vector store index and we'll be going to import storage context okay storage context so these are the things required so let me think what else is required we definitely require open embeding and chroma Vector store okay so list from L index do embeddings okay open okay import okay open embeding okay then some okay L index do Vector stores do choma importa Vector store okay now let's say edore model okay so it should be open embedding that it done now first thing first we are going to read this document rag doc so let's create something called loader loader is actually going to be simple directory reader and here I'll be just going to write input directory I think it is not going to be input directory I think it is going to be input files we just going to read files okay input files so one is still gone and I just going to make copy path okay let's execute okay so this is done right now docs equals to load do load done right okay now let's create the DV okay so DB is actually U going to be DB equals to umal TOA DB got persistent client or something like right and then I need to mention the path part will be SL it is uh inside this thing it should be DB so it will be created here with capital this DB so I just make it DB right now what you'll do we'll be just going to create a collection like so DB do get or create collection and I need to mention a name so maybe nor my tutorial so tutorial 126 right done now what else now we'll be going to create a uh Vector store okay so Vector store now still not data is not available so Vector store will be actually uh choma Vector store okay and there I'll be just going to write chroma collection uh Roma collection it should be CC right just small CC right now we are going to create a storage context SC okay so SC will be storage context do from default I believe from default okay so don't need this thing so here we need to mention the thing so first we'll be going to mention docs is our actual docs accessability shortcuts okay what is this docs okay so docs is there now what else we need docs we need storage context St storage context I think it is uh going to be storage uncore context storage underscore ntxt context equals to okay then embed model embed model is going to be this embed models to embed model all done if I do this thing this is going to create my index uh it is going to actually develop the uh store context storage context name just write index so index will be actually uh Vector store index okay dot from Vector store and inside that I'll be just going to mention my vs VOR one name okay I think it is not is only storage context is going to be in storage contain requ just Vector Stone name equals to vs and here probably we'll be going to reord everything docs sorry I did a mistake actually storage okay right then in model is in model I think everything is fine so first I created uh like collection then I created V store then I created storage context and after that I'm creating this thing uh store index uh from documents initially it will be from documents yeah I think all done right everything is fine okay then if I do this thing this is going to create this thing so let me check so first I created the then I created The Collection The Collection is used in the vector store the vector store is actually used inside the storage context like fine everything is fine let's ex see here with this document rag dog I'm just creating an index it will be created here with a DB folder inside the DV directory so let's wait okay so it is saying uh it is saying loader do load is not there simple directory reader does not have loader. load data load data I did a mistake okay let's see let's do one more time okay yep now it is created here okay so in few minutes the document will be available here let's wait just wait for some time it's a big document so we will take some time yep it's ready okay so something is there right now this part is over because um I don't want to uh develop this again and again right so now we'll be going to develop the main part so that is our app okay so app dop so let's create something app. Pi okay app.py so there what I'll be just going to do I'll be just going to like import all these things okay here I'll be going to import from Open PI import open here I'll be going to import scet as St okay okay so now let's try to actually develop this couple of things first so first develop the client client equals to open okay then St do our application name s. title is actually fire data by with a okay something like that so now query query equals to some question so before that I just uh want to ask some question to the users so it's St do uh text input ask ask your question okay done right this is done everything is fine now everything is going to happen if this uh thing is actually right uh what you said like if user asks something then only it is actually going to happen right or else uh there is no point of doing this thing okay so I believe um couple of things will be going to copy from here I think uh dbcc and this part I think d dbcc uh this part I'll be just going to uh uh dbcc and I think this up to this part we will be going to copy from here okay okay so right fine because it's there and then we be going to uh do the index also from here index is actually index is actually uh vector store index Dot from Vector store now this time it will be from Vector store so Vector store will be here okay right then Capital small Done Right everything is fine right okay so now what we'll do this part is over now we'll be just going to write if if this query if query if I don't know what why every time it is showing me this thing I have no idea it's so much irritating if where is not none okay then we'll be just going to set up a button button is actually s do button inside that I'll be just going to mention submit okay if button okay then what is actually going to happen if button then U we'll be going to write a system prompt okay system prompt okay the system prompt I have already written here uh yeah here so let's copy this thing okay just to save some time I have already written here you'll understand so you are an intelligent AI assistant who has expertise in aurvedic can write nice and well crafted articles use only docs as a context to write the to the question don't do anything make it prop make it prop okay so let's execute up to this point and see everything is working fine or not okay uh okay but before that if button is SK we need to actually do a little bit of retri ret right so basically retriever TR I retriever retriever equals to index do as retriever okay what is actually going to happen uh we going to ask qu and uh similarity top K similarity top K is suppos to three okay right and um I want to actually uh retriever I'm just thinking what else can be done noes okay U see this is not required here so maybe not equals to retriever do retrieve and there I'll just going to pass this query and then we can uh we can check what is actually coming there okay so St dot I think this node is actually kind of uh it's a list actually so let's. WR okay so let's execute this is working or not stream late run app I don't know my my system is actually becoming slow okay app py let's execute so they're just going to ask a question uh what is Benny ficial for we lost let's see it is doing something here okay so immediately it is giving me three documents zero like one like two find so docs is not defined basically here actually it is saying docs is not defined right so it is fine so we'll be going to generate the doc here right so basically it's a list so basically for R so basically I can call it nodes so for noing nodes okay so uh it has what are the things it has let me check first so it has some property called text I believe metad yeah I need the uh I need the value actually so it is part it is inside this text okay so we just need that uh text nothing else okay okay fine all right so basically what will happen you'll be going to just write this uh node. text but this node. text I want to append into somewhere so docs okay now just going to create docs is a blank string okay so basically docs will be docs plus this okay then right once this is done what you want to do I want to just s write dos so let's execute this thing one more time hopefully okay fine okay so this is writing nicely okay at up to this point your job is over but if you want to actually write a very concise information then you can do some additional part but this is good okay right so uh uh now this is done now our system PR is ready right now what you want to do now you want to actually write response response equals to client dot chat dot completions dot create oh than God something unnecessarily create like this then model equals to GPT Pyon 40 like this and here what we actually going to do uh response okay response I think not response response is there so something I do mistakes okay this then and then roll equals to system okay R equals to system and content equals to system prompt right then this then again R equals to this time user and this time content equals to quy this query right all done right now what you'll do we'll be just going to write st. write uh response okay so let's execute and check whether it is actually going to give me the crafted answer or not so yeah uh system is not defined okay basically it's not working yep so let's execute again again maybe some error is coming because the output did not change okay uh massage system uh supported value system M function okay maybe I did some mistake system RO system yeah so yeah this is something wrong actually okay I made a lot of mistakes that sorry yeah now it's working now maybe the answer will be a little bit well refined it is taking some time if you see here okay yes so this is the final answer here okay so basically I don't want to actually write this thing because it is not required okay but we can put a the same like this and now we just going to write response do choices of zero then message then content okay now it is going to give me the refin answer okay now bingo so this will come cool when it comes comes to weight loss incorporating certain foods and beverages known for their metabolism boosting and fat burning properties can be beneficial one such beverage is actually green coffee a popular health supplement d from unroasted coffee there is how Green Copy so basically guys I need to actually rename this tutorial as uh like Advan rag with uh llama index maybe U that will be more useful because uh llama index and Lang chin basically langin and llama index both will be used to actually craft this tutorial okay yeah okay it is saying green coffee okay maybe uh let's see I just want to make it top five let's see how it is actually going to react now okay okay let's see green coffee yep green coffee is always coming okay that's cool that is what I would like to say it's a very interesting tutorial you guys can actually try out the data set I'll be just going to share the data set as well with you because uh or else you have to actually run this generate index uh generate data unnecessarily this is going to exhaust your token okay so so now you understand uh I actually spend a lot of money as well in generating those tutorial here I would like to just say couple of things guys please try to subscribe to my channel hit the like button try to share as much possible and try to get engaged with my channel because YouTube algorithm will check those things whether my videos are getting comment my videos are getting like share Etc so guys if you don't engage with my Channel my growth of the channel will not be fulfilled right because if is so I always try to upload nice and quality content my videos are not Theory driven I always try to do something uh creative so I need little bit of help from all of you guys guys please help me to reach my goal and please try to subscribe to my channel this is an uh this is a very very uh humble request guys please please help me to grow okay that's it that's it for today we'll see you in the next video till then take care goodbye have a nice day and happy learning thank you