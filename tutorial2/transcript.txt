what's up guys this is Ronnie welcome back to our Channel Total technology Zone and today's topic will be how to build Q&A app with rag using Lang chain okay so this is going to be a little bit Advanced tutorial and I believe I already um discussed that I'll be going to start some uh really exciting stuff I believe in the last tutorial so um here is the tutorial so in this tutorial I'll try to actually develop one QA based app using uh using langen and obviously I'll be going to use the concept of rag okay so before I um do any further coding I think I should explain what is rag okay so let's start with the next slide so what is rag so rag is a technique for augmenting llm knowledge with additional data okay so basically uh augmenting means adding some external knowledge to the llm for example before I actually read through this slide paragraph let me explain you in simple English language okay so suppose uh suppose you have Wikipedia page which is uh created two days back right and you are using open AI llm okay so now open a llm is actually uh uh not real time it is actually using the data I think up to June right so when I'm recording this video it is actually January uh January 18th 2024 and open a is actually updated with I believe something around June or something okay last year 2023 so if a Wikipedia page is created two days back then op a LM is actually not going to give you the correct answer if you ask something related to that Wikipedia page right so in that case what is required you have to actually read that page you have to actually par it split it and then you have to actually store somewhere and after that whenever his user is actually going to ask you some question you have to actually uh identify the similar uh like uh identify the similar thing like this Bas on the user question from the store uh like stored information and from there you'll be able to actually use the underlying llm that is open llm to generate the response so that is what actually wrote this paragraph So basically I wrote means I just copy and paste it from the Lang chain official documentation so let me um uh read through this thing so llm uh can reason about wide ranging topics but their knowledge is limited to the public data up to a specific point just now I explained right and and in time and they are trained also so basically open llm just example open LM is actually train up to uh not real time data maybe something uh which is happen in the world globally till June right now if you want to build an AI application that can reason about private data or data introduced after models cut off date cut off date means suppose you have created something after June June or maybe you have some very private data maybe some PDF file which is available on your local if you want to actually ask through something right then that time you have to actually introduce those additional data to your llm knowledge so that thing is actually known as a rag so the full form is rag is actually retrieval augmented generation I know this is kind of a very boring if I just read through the slide but again it's a formality to give you guys a little bit of idea what is rag so rag means you want to actually get some information uh from some data which is not part of the llm okay so for that reason you have to first load that data you have to actually uh send it back to the llm during the time of uh prompting right so so let me go to the next slide so rag workflow so basically a typical R application has two main component one is indexing and second one is actually retrieval and generation so indexing means a pipeline for ingesting data from source and indexing it this usually happens offline so here actually it is showing it is offline but when I'll be going to do it so that time it will be on a flyer will happen so let me explain this thing what is indexing so indexing means is actually if you say here load split and store so basically it happens offline means uh you are going to create a store and that store is actually going to be used with uh llm whenever user is actually going to ask any query so the data store is only going to be updated only once so that is why they call it as an offline okay so the first part of the induction is load so first we need to load our data so basically it happens using Lang chain document lader I believe all of you are familiar with this thing if somebody's new guys please subscribe to our Channel and try to actually watch the playlist from the beginning so we have multiple tutorials created on document loaders okay so next part is actually split so text splitter again we have done multiple tutorials on text splitter so text splitter generally helps you to actually split or break the uh large document into smaller chunks right we know why we are doing this thing and after that we need to uh do actually this smaller things are actually useful for indexing right and passing it to a model will be very efficient if you just pass the smaller chunks okay cuz larger chunks are actually harder to search over and it will F the models like search window right or next thing is actually store so we need to actually somewhere store our indexes right so they can be search on later so maybe whatever you are searching you want to actually uh do it again on the later some other time right so that is often done using a vector store and open AI embodying model so suppose you created a store and you can actually use that store again and again to actually query this thing but in this tutorial I'll be not going to do anything offline CU everything will be on a flly CU I'm just going to create a a console based application so when I'll be going to do let's say real application uh like some sort of like application typ of thing then that time probably we'll be going to use this persistent Vector store okay but for the time being we'll be going to do everything on a fly okay so last part is actually rable and generation so R table gives a user input so given a user input relevance split R from the storage and that is the vector store and using a retriever okay so basically retriever means uh user will be going to give an input and based on the user input it will search the splited documents from the vector store using a retriever okay and generate means chat model and open llm is actually going to produce the answer based on the prompt okay so that's it and a little bit of workflow in the diagram so load split embed store so first you will load the data then you'll split the data then you'll be going to embed the data and after that you'll be going to store in a vector store and next part is actually Ral and generation user will ask this question the question will be actually going to be embed uh sorry going to be add with the retrieval so retrial is actually going to get the information from the student after that LM is actually going to generate the answer based on the prompt and the answer is actually going to be generated so that is how it is okay so I believe uh more of uh it's actually the largest Theory or the longest Theory I covered in this series maybe more than five or 10 minutes I just keep on talking so I also hate to talk so basically let's try to actually do some sort of coding before I do the coding let me explain what exactly I'm trying to do so this is a page so basically uh I hope you already know that I'm from India so basically India is a cricket uh like cricketing Nation so we play cricket a lot so basically what I do I have a page which generally gives information about the latest match uh the all the latest matches are played between a different nations so basically a couple of days ago I think not couple of days uh I think last day yesterday actually there was a match played between India and Afghanistan so here's an information about this match so what I'll do I'll just try to actually first load this page and after that I'll be going to split index and store in the vector store and after that I'll be going to ask some question and we'll see how the responses are going to generate by the open llm okay so we'll be going to do it now okay so okay so you can actually do the same thing using some other URL okay let's see so let's start writing our code so first we'll be going to import the models sorry modules okay so it should be from Lang chin okay dot document loaders so first I'll be going to load Asing chromium loader okay so it should be a sync chromium loader so this is actually going to uh you going to be used uh to load the uh URL um in text format okay not not a textt format HTML format okay then after we load this data I need to actually convert this HTML into text so HTML to text Transformer will be going to require so for that I need a Transformer Lang chain. document Transformer or something okay let's see yes sorry okay so import so basically HTML to text Transformer right then what will happen so basically now after this thing we'll be going to actually uh split the document right so we'll be going to use from L chain do text splitter so we'll be going to regive character text splitter right it's done then we'll be going to actually store it in a vector store so now we be going to import the vector store so from Len chain do Vector stores import chroma right okay all done now next thing is that we'll be going to use embedding with the uh Vector store so basically from Lang chain dot uh embeddings okay so this is going to be open AI embeddings right done then last two things is actually required one is actually a chain uh we'll be going to uh uh import the red table chain and we'll be going to import the uh chat uh chat models chat open AI okay so from lank chain okay do chat models import chat open AI right and last thing so it should be from L chain dot uh chains import uh we going to import retrieval I think r q right okay so that's it so what will happen now so I'll be going to actually start writing the coding so before I do the coding so let's actually first load the URL so basically let's say Ur L's so this is going to be a list so this is going to be something maybe let's copy the URL okay okay like this now what will happen so let's say loader equals to as syn chromium loader and then so it should be URLs equals to this URLs okay done then we'll be just going to write so this is going to be HTML document so HTML docs equals to loader. load and then we'll be going to convert this as a text document so for that we need to use this Transformer so Transformer so TF equals to HTML to text Transformer and then we'll be going to get the final document FD so basically it should be uh TF TF means this one dot transform documents and inside that I'll be just going to put our HTML documents okay and we'll see if I'm getting this thing or not FD or not okay so here actually we're doing the loading part then we'll be going to do uh splitting and then we'll be going to uh store it in the vector store by indexing okay okay so let's see uh what is this it is saying uh okay so this is something wrong I did so it should be TF do uh transform documents okay so I just wrote something different okay so let's see yeah it's coming so no problem at all so now what will happen we'll be going to actually uh create the tech splitter right so TS is Tech splitter okay so it will be recursive character text splitter then it should be going to write chunk underscore size let's say chunk size should be th000 okay and then what will happen chunk overlap Okay so so chunk over L is zero okay then we'll be going to get the split documents right splitted documents pits splits okay so it should be TS do U uh split documents split documents and inside that I'll be just going to write our final document FD right so our final document FD is actually here right and then what will happen we'll be going to actually um so up to this part everything is done right now what we'll do we'll be going to create our llm okay so now just uh splitting first I actually loading is done then splitting is done now I'll be going to actually store this thing so for that we'll be going to require embeddings and Vector store so let's create an llm so it should be chat open a okay so model equals to GPT i 4 and and let's say we'll be going to use a temperature of 0.8 right now what will happen we'll be going to create an embeddings okay embeddings so embed be d d i n gs embeddings equals to openi embeddings okay very simple now what will happen I'll be going to create a vector store using chroma DB and we'll be going to store everything inside that so basically chroma uncore DB equals to uh uh what is that okay I think it should be Capital C see HR o m chroma okay so chroma dot uh it should be chroma uh I just solve it uh chroma from documents from underscore documents and here you be going to write so basically so documents equals to splits this one right so s p splits then comma then what else will be required to pass the embeddings embeddings equals to embeddings okay so let's see up to this point everything is fine or not we are able to fix this thing up to here means everything is stored here let's see if there is no error it means our document is actually loaded then splitted and actually stored inside the vector store so it is saying chroma has nothing called from documents okay so so now there is a problem okay so I did a mistake so that is why documents m n actually so now this will work I always do a mistake okay so let's see eddings so why I'm getting this thing okay so this argument is again unexpected so there should not be any space It should be just embeding okay see it is telling so no need to remember anything they will tell you what you are doing mistake what mistake you are doing okay okay so let's see what else now okay no error so now we'll be going to write a query okay so query is going to be anything I don't know what is the query we'll do it but let's create the Chen Chen equals to now retrieval QA right then from chain uh from chain type right and what will be inside the chain then llm equals to llm right then I think then then then then chain type will be stuff right right and we need to now pass the our Vector store so retriever Okay so so retri t r i e v e r so what will be the retriever so retriever will be chroma DB dot as as ret right underscore r t r i e v e r right so all done so let's see let's execute this thing and and see whether this is actually working or not okay let's see and then we'll just run the query okay I think yeah it's done it means no error so basically what we'll do we'll write response equals to we'll be going to run this query now so how we'll be going to run so the chain and chain is actually going to run the query and in the print I'll be going to run the response print response okay now what is the query so first thing I'll be going to write who won the match who won the match between India versus Afghanistan okay of Afghanistan okay so basically India won the match right so basically it's written match TI India on super over so something similar it should uh generate so let's see how it is actually going to generate okay so I'll be going to ask maybe five question because the video is already a little bit lengthy so you guys can actually try and test this thing once I share the code via GitHub okay so let's execute okay let's see I'm exciting I'm excited actually it's an exciting thing okay the match between India and Afghanistan was tied however India actually see this thing how cool this one okay first question is done then probably uh I can write who was the top scorer from India between between India Pakistan indistan match okay let's see whether it is actually going to give me anything similar or not okay so okay so the top scorer for the India in the match against Afghanistan was Rohit Sharma see it give me so now let's ask a different question two question is done where was the match played where was the match played between in the and Afghanistan okay so third question so let's see okay so see clearly it give me the answer the match between indiia and Afghanistan was played at chinami stadium bangaluru that is the right answer okay and let me check here yes bangaluru see right it always gives the correct answer so three questions are done let me actually try something different uh what was the score of verat GOI on the match between India and Afghanistan let's see see a tricky question let's see vat Koh scor zero so let's see whether it is actually able to find it or not okay okay Barat kohi scored zero runs in the match between India and Afghanistan so cool so four out of four all are correct okay right so Co s ining scores rinking score okay so let's ask this question okay last question okay let's see okay okay so ruing score in the match between Afghanistan so it is not giving any answer so let's see uh let's see okay maybe ining scores okay so let's see okay now it is giving me the answer see in the match between India and Afghanistan Ling score 69 RS okay okay I believe that's it guys so you guys can try and test something more out of it and again this is a very new uh tool developed by langen so sometime you will be going to get uh like negative answer as well so it's an humble request try and test this thing if you want to give some feedback go to their Community they are very nice people they will accept it and they will try to actually uh modify or develop this feature in the upcoming things but it's a very very amazing uh like um uh what you can say it's a module available so that uh we can actually develop our AI based application very easily and fluently okay so I should conclude this video here I am super excited cu the next videos are going to uh super challenging and exciting as well so I hope you guys are also going to enjoy those Series so guys before I conclude this video this is an humble request guys please try to subscribe to our Channel hit the like button and also try to share our videos with your family or friend whoever you think we get some benefit out of this thing okay and last but not least uh whenever you are actually watching this video once you finish watching the video just try to write The Code by your own if you skip the coding part you won't be actually able to learn anything because the coding is actually going to uh give you the confidence and this is only going to clear your doubt and understanding and this will actually help you to enhance your skill set cuz see in this half an hour I'm not going to teach you the entire thing I'm just only helping you to actually develop your intuition towards this Technologies like what is Rag and how you can use it but when you join in a company on maybe when you start working for a client there the magnitude of the implementation will be entirely different right to make you Future Ready Or futuristic uh development uh ready I'm just helping you here so that you can actually do those Stu very uh do those jobs very easily so that is why just try to do the coding by your own okay don't skip the coding okay so uh that's it guys enough of today we'll see you in the next video till then take care goodbye and have a nice day and happy learning n