what's up guys this is Ronnie welcome back to our Channel Total technology Zone this is tutorial 112 So basically uh just let me review this this is the tutorial 111 so so obviously I have already uh uploaded 111 videos before that but this video is very special and I'm actually uploading this videos Almost after a year okay almost after an year okay so basically the topic is NE 4G ingestion using spark connector from data so basically um I'll be going to show you guys how to ingest data inside Neo 4G using spark connector so the tutorial is very straightforward from the tutorial maybe you guys already know okay what is what is big in in this tutorial what is new basically the spark connector released three years ago then I'm actually uploading this tutorial now so basically uh maybe this uh spark connector released three years ago and maybe a multiple like contents are available in the YouTube but the surprising thing is actually that I also under I was also under the same impression that this topic has been covered already some content creators are already created this thing but the problem is actually uh no one actually showed uh in a Hands-On manner uh by uh uh breaking down the steps in a like a small stepwise approach that how to actually load the data or how to ingest the data from uh from data uh like bricks uh sorry from a data bricks table uh to neo4j okay so basically that part is missing like whatever videos are existing that talks about like some theoretical and conceptual part like those topics are very very very good actually but this is something where actually I'll be going to explore the Practical approach like I'll be just going to uh do everything in a Hands-On manner so that you guys will actually understand because for last couple of months I got maybe 200 requests that please upload a video on how to inest the data using spark connector so what I did every uh like what whenever I get this response I actually get this comment I just responded back that search this topic in YouTube you'll find a lot of video because I when I search with using this thing I saw maybe 100 videos are available but none of the videos are actually talk about the real injection so this is the first time someone on YouTube someone on YouTube is actually doing the live inje using spark connector that to from data bricks Community Edition okay so what I'll be going to do in this tutorial I'll be going to load a large CSP file into Neo for spark connector okay so there will be a CSP file I'll be going to use that CSP file to load using NE for spark connector so python will be used as a programming language anguage and CI qu will be used to actually write the data into NE for so let me now break down the steps so first I'll be going to create a data briak table by loading the CSP file the large CSP file then I'll be going to load the uh table as spark data frame using p spark then after that what do I'll be just going to write down the uh spark data frame into neo4j using the spark connector these are the overall steps right so now some bookkeeping or housekeeping activity let me actually open this thing uh I think this one okay so basically if someone is actually watching my channel for the first time or if you had just come across this video for the first time you don't know about me or my channel so basically if you go to YouTube and search for Total technology Zone you will find my channel and inside my channel just go to playlist you'll be able to see I have created a more than 111 videos 100 exactly 111 videos on NE 4G using python okay so if you are fasinated about uh like graph technology Neo for or graph data science or you have aspiration to like build your skill towards jni because graph and JIS are actually going hands in hand okay so basically if you want to actually become a data analyst or data scientist or AI engineer so basically if you want to build some rag driven application so basically you can start with graph models graph modeling then NE 4G is a very good entry point so you can actually watch my Series so I just give you the reference okay and if you really like my work guys it's a humble request please try to subscribe to my channel uh hit the Bell notific ification icon so that you should not miss any video from the future updates and also try to share our videos with family and friends and the last but not least uh after watching my videos just let me know I have some sort of feedback whether you uh like whether you are satisfied with the content whether you think something could be done in a better way or if you really like the video or it is helping you to actually do your work or gain some knowledge please let us know by some sort of feedback so that it will motivate Us big time right okay so first thing first first we'll be going to set up the data breaks Community Ed basically you have to go to this link and you have to actually um create a datab BRI Community cloud account okay once you create the community cloud account you'll be able to see something like that I'm not going to go through those sign up sign in those steps like all you are mature you guys can figure it out so just this is the link Community cloud. dat.com or else if you just search in the Google databas Community Edition sign up it will give you okay so once you uh do this thing here what you have to do with have to come here and your workspace is created here this is your user so inside that what you have to do you have to create a folder okay so I'll be going to create a folder called Dev okay or maybe I just going to create a folder new forj inje okay first thing okay so new forg inje created right okay so basically there is no cluster created right so I don't know uh something I created last time so because of that it's coming so basically what you have to do first have to click on catalog so basically nothing is there so first you have to create a table you have to click on catalog have to create a table so basically I'll show you I have a file here if you see here so let me open this file with Excel uh with Sublime Text okay I be not going so basically this a uh single column of the file okay and I have a big file here Ecom CSP basically it's an e-commerce file okay okay so basically it has 300K record okay so 300K 300,000 so even time order ID product ID category ID category code brand price and user ID so basically it's a e-commerce like data from a website so basically every Ro talks about a order whenever a customer place an order that detail is actually here so basically when the order was purchased like even time order ID is their product ID for which uh product uh this order was placed what is the category of the product what is the category ID of the product then brand the product belongs to which brand what is the price of the product and who is the user who made the order so that is the thing so I'll be going to create a nice looking graph from this thing okay so first you have to create a table with this data so how to do it so basically you go here and create table and it is saying that uh I have to actually drop this thing here okay so let's wait so it's getting uh dropped so let's wait for some time this is actually a 300 MB file so we have to wait for some time okay okay let it load so let's wait for some time okay so basically it's work in progress kind of a mode is going on okay okay 90% has been done maybe okay it's it's happening very smoothly so basically in this way guys you can create a like a data break table as well inside your catalog okay it's a very straightforward thing okay okay it's done so now create table with UI okay so I have to create a cluster so I don't have a cluster created so first you have to create a cluster okay so when you are going to do uh this thing for the first time you have to create a cluster okay so okay so this is not going to be possible because I don't have a cluster so what you have to do first you have to go to compute and after that you have to create a create compute okay I have to give a name so basically I'll be going to give a name Neo 4J underscore injection okay so Scala is actually 2. 2.2 and Spark is 3.3.3 right you have to remember because these things are important for actually uh installing our spark connector okay so NE for so basically let's this instance everything is actually here okay okay okay create compute so it's getting created let's wait for some time okay so let's wait and after that we'll be going to install our necessary python libraries okay let's do the cluster creation part first okay so this is going to take at least 2 minute so basically I think it is created on AWS so basically the region Us West 2 a okay okay okay let's wait for some time okay it is still running so you have to wait no other option right if you want you can just keep the video I don't know like at which minute it is going to be finished but let's wait for some time okay okay so it's done okay so now what we'll be going to do I'll be going to click on it and I'll be going to first uh click on libraries so basically uh what you have to do uh we have to install some libraries like install now so basically uh now the important thing first you have to install the ne for spark connector so basically you have to go to this page sorry and you have to actually click come down to this page and if you see here it is saying if your Scala version is this and scale our our Scala is actually uh um a spark so basically with Scala 2.2 and uh spark this is and with Scala 2.2 and 3.2 and above it is this so basically you have to go here and you have to check your version cancel it and you have to check configuration so basically our Scala is 2.12 so basically uh 2.12 this row obviously and what is our spark our spark is actually 3.3.2 so basically it should be this one right okay so now how to actually download that so basically there should be a link somewhere okay okay let's slow down okay so quick start okay installation is here website yes so basically you have to go to this page and you have to click on new forj connector page right and after that you have to download right so basically if you click on the download it will come with this link you have to do it okay so basically I already uh downloaded this thing so basically this thing is available in my computer this thing okay and here and after that if you unzip it it is going to give you this so basically basically what is here this is the thing um uh so basically it is if you see it is for spark Scala 2.13 and it is actually Scala 2.1.2 right so basically our thing will be this one right so what you have to do this jar file you have to go here and you have to click on libraries you have to click on install and you have to just put this thing here so basically just put this thing here so spark 2.12 right once this is done you have to click on install and wait okay select the installation to be completed so this is to install the spark connector without this thing it will not work okay so it is done so now I'll be going to install other python dependencies so first thing Pi Pi first thing uh obviously we'll be going to require P spark okay let's install by spark we'll be going to install new forj okay okay P spark NE forj then if you're going to do something else then probably you can do pandas I don't think so it will be required but let's just for safer site let's do it and probably I can install numai but I don't think it will be required because once we install pandas by default it is going to install numai okay I think this is fine this is fine so let them install all these things okay so that is how we install python dependencies on a datax cluster I believe all you all of you already familiar with this thing okay uh why I'm doing this thing from the beginning because most of you just started working on this data braks thing and actually landed up to a new forj project right for data inje for them actually this is going to be a super helpful thing so guys please if you really like my work please subscribe to my channel and also try to share my videos with your family and friend and try to bring um like uh more and more audience towards my channel that will help us to grow actually okay okay so let it finish until then we can wait okay after this thing we'll be going to create the table okay so spark is installed if you see new is spending npay and pandas is spending so okay let's wait okay it's taking time okay let me refresh the page I don't know why this is taking time okay it's really doing something on the back end okay till the time cluster is created I can create the table so create table okay so let's dump the data so Ecom do csb so this is also going to take some time right so let it run this is also going to take at least a minute okay okay okay so it's done then you have to click on create table with UI and after that you have to select the cluster 4G inje then preview table okay so let's see what is going to happen now my data is huge actually so okay so it came so basically what table name you want to give so I just going to give Ecom so first row is header right so let's wait let's see how it is going to preview the data so I have a huge data so basically because of that it's taking time okay so you have to wait no other option right okay let's wait yep so data is coming let's see this event time this is order ID this is product ID this is category ID string brand price and user ID right okay all fine so let's create the table okay so what it will do it is going to create the table and this is going to take definitely some time so we have to wait no other option right okay so yep let's see how fast it will be I can see it has like 15 like GB of RAM so I don't know whether it is created or not so it says it is created so what I'll do now now go here and check yeah I have the table right so now what I'll do I'll just go to compute and I'll see the cluster and I'll go and check the libraries like all libraries are installed like um cluster is created right cluster installations are done uh CSV is loaded as table right now next thing we have to check whether I'm able to F the record or not to do this thing what you have to do you have to create a notebook that is where we'll be going to write our code so go to your workspace click here right okay click users then this is my user there I created something thing called this folder okay so inside this folder what I'll be going to do I'll be just going to create okay let me delete this thing I I think I don't require this thing okay I don't know what is this how it came okay so let's do this thing and here I'll be just going to create a notebook okay so I just created a notebook okay so notebook is created it is attached to the new 4G injection like cluster so now we'll be going to just run a SQL query like this if you want to run a SQL query using this uh datab bricks notebook you have to use like that see is change here SQL but by default it's python okay so what we'll be going to do select star from Ecom right and I'll be just going to get limit 10 I just want to check 10 record just a SQL query okay run sale so see how powerful is this thing I got my data so table is already populated and I'm getting the data so everything is fine now what we'll be do what we'll be uh actually going to do we'll be going to creating a uh NE for sandbox okay so let's go here neo4j sandbox just search in the Google you'll get this link sandbox. neo4j sandbox.com and then launch sandbox launch free sandbox with this link and let's see whether I have a sandbox already or not okay so something is created blank sandbox okay so what we'll do I'll be just going to click here and go to connection details don't worry guys I'll be going to delete this thing so you won't be able to use this thing anymore so I have the IP address so I just copy this thing here okay right with uh sorry it's not copy it copy to clipboard then this sorry what is this then 74 okay right let's see whether it is opening or not it's opening then just copy the password username is NE for obviously so I'll be just going to type the password here and then I'll be just going to post me for here and paste it okay let it run okay done so it's fine right everything is working fine so let's see whether I have anything here or not okay so match in return count of n right so I have nothing right nothing to worry okay so let's do one thing let's try to work on this thing now right so first thing first so it's already here I don't want to actually use this thing anymore so let's uh Delete the command and let's start from from the beginning okay right so first thing first we'll be going to import all the necessary libraries okay right right MH MH uh okay so just hold on I'm just getting a call okay mhm okay so it's not a hen call so let's try to actually import uh the things first okay so first thing first we'll be going to actually do from P spark dot SQL import spark session right and then we'll be going to create the spark session okay so maybe I just going to create spark equals to spark session right dot Builder right and then we'll be going to write give app name app name we'll be going to give like new forj inest inest okay and then so what exactly it will be like uh uh you can like get or create right get or create that is the syntax okay so let's run run first run this thing first okay so here run the cell okay so executed now we'll create another cell so here I'll be just going to actually load the data from SQL and convert into a data frame so basically what we do we just create DF and it should be like spark do SQL right and it'll be just going to write like this query first uh select star from Ecom limit limit 100 first do the limit 100 okay and then we'll check what exactly is going to bring right this is going to be a spark data frame okay okay so it's coming so fine so we have to just use show so this is going to give us the value as well it's not like a pandas data frame okay so everything is coming all right so what I'll do I'll be going to do it for thousand I just I'm not trusting the cluster capability it is showing 15 GB but I'm just going to do it in a batch so let's see whether it is able to do it or not so it is able to process th I'll be going to do for 100 10,000 see how fast it is going to do last time it took uh 50. 54 seconds like let's see now 10,000 record now I'll be going to do it for 100,000 record so it should be at least let's see how much faster it will be run cell oh only4 seconds extra so it is 100,000 now let's do it with uh 200,000 okay okay okay so it is uh like more faster okay so I don't know like why it is that so let's actually remove this thing and let's uh run it okay okay right so all done right so everything is loaded right okay so this is loaded now next thing is actually we'll be going to pass this thing into a cipher query so first we have to build the cipher query right right so to build the cipher query what exactly you going to do we'll see it now so let's first build a cipher query so maybe SQL okay Cipher query so something like this and this so basically uh we just write DF and see what exactly is there okay so this is the column like event time is there order ID is there so I'll be going to create like order okay I'll be going to actually do a data like modeling as well okay draw.io understand first okay okay okay so like this like this okay fine now basically uh let me actually open the cluster now again my cluster okay so what we do uh we just actually do DF do show okay okay so basically if you see uh okay it is not coming properly here what we going to do actually okay just do one thing so in again do a SQL query and you see SQL and select star from Ecom limit 5 okay let's understand this thing I'll make you understand then I'll do it okay like event ID order ID right so basically when a order is getting placed it might have two properties like order time and Order ID so first it will be like this so basically there will be a note called order right right and order is actually placed by a user if you know order gener placed by a user so user has a property uh like user ID is only property so basically there will be another node user right user so basically user placed an order so basically this is a relationship name user placed order then order placed for so basically met for there is a relationship called madeore 4 for a specific product right obviously right right this this is a graph right so basically you will get it from here again product so product basically has a product ID product brand product price this three things right and product generally belongs to uh brand and brand has a category right for example product is a mobile mobile phone mobile phone has a brand right maybe apple and Apple has multiple categories right right so like this so let's and category has two ID category ID and category code and product is actually product ID is only one thing product brand is on one property and price so product has three property product ID brand price right and then here product belongs to a brand right and brand has a category right so product has Brand uh this product belongs to this brand and brand has category has this is category right so we have to actually build this relationship or build this graph right so how to do this thing we'll see it now okay so first what we'll do uh we'll be going to actually uh do it uh for only one only one record okay and we'll see okay so let's do it first okay so what is this just's build a SQL query first okay so SQL query will be create o or maybe can create a Marge both are fine right Marge o order okay so order ID equals to event dot even dot order ID will be coming from where order ID and Order time so basically every Row in the spark data frame is called as an event okay and event dot is actually going to give the specific column so basically order ID like order underscore ID then order time order time is actually going to come from event time so it should be event. event time like event can write event dot event underscore time right this is done right so now what will happen uh we have to just write uh I don't know let's do it okay like this uh okay first we'll see uh I'll I'll I'll actually run this query somewhere and I'll be going to show you actually then we'll understand okay how the merge things works so I'll show you something so maybe I can just write merge a employee okay let's say name Ron and then we can just do another like B right uh let's say company something like that and name equals to FB okay like this and then right um Okay so and just do this thing yeah so this will work so what I'll do I'll be just going to use this thing and and at the end we can just merge a like this mer as B right so sorry so I just need to actually first delete me delete everything match in detach delete and so let's delete everything first okay now let's do it okay added two levels added two relationship two properties and one relationship is created so basically uh match in return in let's see okay right so basically we'll be going to create use a merge to do this thing right so basically uh what is actually going to happen so let me do this thing here where is this thing okay so merge this thing then we'll be going to merge like U of A user right so basically user underscore ID equals to event dot event. user ID right event do user uncore ID right user uncore ID the next thing is be next another merge right here okay so there will be total five nodes so the user placed an order order made for product so basically this will be a product right so product has couple of things like product as product ID brand and price right so maybe brand and going to be event. brand right right brand then product ID then product underscore ID equals to like this event dot product uncore ID right okay and then we have price so basically price equals to not equals to basically even do price right so order user product then next will be brand right merge merge B brand brand has only one thing that is actually brand name right okay so basically event. brand so I can just make it small so brand has category right merge C category and then category underscore ID is equals to copy event dot category ID then category code event. category code now we'll be going to actually merge everything here so basically merge o merch U user list user plac order right then order met for product right then product belongs to Brand right B now B have C that is category right all done right this is done now what we'll be going to do we'll be just going to run this query right now what it do now let's delete this thing right now let's add this thing now let's do the spark part okay okay so this is going to be really interesting now I'll be going to just uh do the spark part now right so basically what will happen it will be spark uh spark uh so not spark it will be DF DF is a data frame dot WR right dot format so what is the right format org. neo4j do spark data source okay so basically it should be org dot neo4j do spark do data source okay okay and then like this right then option okay in the option what you will be going to pass we'll be going to pass URL like URL of our NE forj inst so we'll be going to get it from here so we'll be going to get the bolt URL copy to clipboard go here and paste it right this the next option will be authentication basic option right so what we'll be going to write here Authentication basic. username right authentication basic dot username right what will be the my username my username is always Neo forj right then we'll be going to do it for the same thing for password right so what I'll do I'll just going to copy this thing you know I'm a very lazy person okay basic password and what is the password we'll go here we'll copy the password from here okay let's let's let's come here and paste it here right right then uh we'll be going to actually um the batch option something like this then I'll be going to mention batch do size uh okay I'll be going to do best s for the moment let's say th okay and then something like this then do option then query which query you want to pass query and our query will be cql cql is actually this variable right right okay I think um just hold on okay then what else I'm just thinking uh everything is fine right mode may be happened okay and then do save right so if you execute this thing this should run but what I'll do I just don't want to actually mess with this thing so basically I just going to do it with a one record so limit one okay DF okay one record is coming now let's query this thing and now what we'll do uh I'll just go ahead and check what else is there uh there should not be anything okay so match and return and nothing is there right so now let's run this query okay so it should create the graph for one row okay so it started so running command okay something is started let see how this is going to spark job is started so spark session build spark jobs are going to happen now okay so it is saying that everything is completed okay within 11 second one record for one record it is taking 11 second so now let's do a match and return return in yeah so okay so this is the thing this is a cool thing right okay I don't know okay so basically uh user placed order okay this is the user placed order this the user l order order made for this product brand price and this thing right then product belongs to this brand Samsung and Samsung has this thing right this thing right this so basically uh there should not be duplicate record will be created for user there should not be any duplicate record created for uh like uh I think product could be same okay brand also could not be duplicate and category should not be duplicate only this order must be replaced right so now I think these things are working fine now what I'll do I'll just going to delete this thing okay and now what you'll do I'll just go ahead and do it for let thousand so basically uh I'll just make it in a small chunk 100 and I'll just try to load the, okay so let's do it for th000 so th000 is done right now let's do it for this thing let's see how fast it is going to do it so ideally it should be going to create for thousand record right so so let's wait so one row it is taking 10 second for for let's say uh okay so it is saying that uh okay so now the problem is that something is null uh because of that it actually it is going to show some error okay so basically uh there's something if some properties are actually having null value then probably you have to do some ETL jobs right so you have to actually ulate those null and other stuff right so for that what you have to do uh you can try catch this thing okay and whoever is actually having null properties those will be actually eliminated by NA properties right so that will be the next step how to actually do it within ETL okay so if a if a if a data frame column is actually having null values or no values then how you are going to actually tackle this thing that will be the next thing we'll be actually going to do that okay right so um we need to actually fix the problem of actually replacing the rows where actually null value is there or uh nothing is there so we have to actually make it na okay so before I actually start let me just explain the problem one more time so I have nothing in the graph right now what I do I'll just try to load this thing again one more time so let me actually do it for this thing again okay uh let's wa it for one more time here uh and let's do it again so hopefully we'll be able to actually get some error yeah yep so if you see some cases brand is null so basically if you just going to fix the brand maybe some other columns maybe uh will come in the future so actually the problem is we have to actually fix it from the root like whenever the column is actually down we have to actually replace it with something called na okay so let's do to it now okay so from so basically P spark so basically py spark. function so why something is no it is the SQL function so SQL function import so basically call and one more function is when right so now what we'll be going to do right it's done then what we'll be going to do so for column c o l u MN column in DF do column so basically DF do columns is this actually our data frame DF do column is actually going to list of all columns right so now what we'll be going to do we'll be going to create the resultant data frame with DF okay so it should be DF dot with column right with column and basically so we'll be going to write column column and then we'll be going to write when when is a clause when uh when call of this function call call of uh column do is null okay so column dot e null where is null I don't know uh okay I think it is not coming yeah is null so basically uh let me check is null okay so basically uh when will be applied here and the entire thing is actually okay so when is applied here in column and then uh call of column is null so basically let me actually do something so something like this okay so for this there will be something but right now it is like this okay and basically and this and then uh when and we'll be going to create a or function like this okay so maybe or or maybe uh call of let's say column okay so it should be equals to equals to blank so something like this okay so in both cases what is actually going to happen so maybe I can just write this okay this if it is true then it should be na right na right so n and then we going to do something called dot otherwise otherwise the value should be like this call equals to column column 1 2 3 okay right so basically I think this bracket this bracket this is here this bracket is here done this bracket this bracket this bracket this bracket done this bracket this bracket done and this bracket is actually this bracket okay everything is done right okay so I believe everything is done so let's do it uh line two there's a problem what it is saying invalid Sy oh okay it should be for sorry sorry guys okay yes it's done right now everything is done now I'll be going to actually run this thing let me check whether I have anything or not I have nothing okay so let's going to execute this thing I have total executed 10,000 and my best size is actually 100 uh th000 so it will be going to process th000 row at a time okay so execute okay so execution started what I'll do I'll just go ahead and check so the number should be increasing not increased okay it is processing 100,000 record at a time yes 2, 528 it's going so great 4,673 okay it's going good okay good okay fine so let's see so no error means it is pass the text pass it has passed that uh like exception okay so it just did a small here okay to like convert uh all like null value or all like empty columns with a value called na there's a standard procedure in any data engineering or data analytics project or data analysis project right so let's do it okay so it is 8,666 okay so numbers are increasing here as well right so yeah it's school it's going on and after that I just try with a little bit like larger record and we'll see okay let me check how far it is 10,000 so BAS basically every row is going to consist of maybe five so this is my data model so 1 2 3 1 2 3 4 five five five notes will be created for every note but again this this this this should not be duplicated this should be like U obviously there should be more than 10,000 because 10,000 is always the record like order for every order there should be another four columns so let's see how much so at least I believe there should be more than 12 or 13,000 record will be there right let's see so let's see how many order out of this 10,000 matcho order returned count of O Let's see 49 83 4,983 right so this number should increase 5,815 okay 5,800 okay so overall maybe 15,000 or something yeah 14,1 184 right so toal total relationship is actually 27,000 if you see belongs to have made for placed right so 6,066 so total 15,000 node and there is something called 31,000 relationships are created right okay 6,606 right okay 7,425 okay so guys the video is actually going to be stretched if you don't want to actually watch it it's up to your choice but I just want to uh like uh don't want to actually pause the video like if I pause the video maybe I will get some error and where actually it will be difficult for me to again create the scenario and explain or reproduce the error right so it's better just keep everything like this okay so it's done so it took actually 5 minute for creating this many like this many notes like 8,260 notes and Order notes and where actually 19,000 uh like like total number of notes and this many relationships so basically if I create on let's say let's click on a brand right so let's say let's say how many brands are there okay let's say there is brand called H what is Apple I don't want to see apple I want to see actually Apple I can see didn't came M or what this is strange okay so total 290 Brands came okay right okay so maybe brand where n. name equals to Apple okay I forgot to put return statement return n yeah Brand Apple let's see how these things are connected how many orders are actually placed from Brand so this many see right this is very fascinating right okay so now what I'll do I'll just try to actually delete everything and after that I'll just try to actually load this thing for bigger but I think uh I should not delete this thing cuz anyways it's a March query so it will work so what I'll do now I'll be just going to actually uh put this thing without limit okay let's see run the cell right it's done then query I don't want to change anything but here I have to actually change this thing so this is done now let's run this thing and maybe I can increase this thing for 5,000 okay and I'll run it and I'll actually keep keep on running this thing and after that I I will just uh let you guys know how this things is actually going to react okay so keep this thing running okay I'll just let you know the result I just going to stop it here and in between if I'm going to get any error I'll let you know because once the video is over I'll be just going to upload the same data file and I mean the same CSV file and the same notebook code VI my GitHub link so you guys have to practice this thing but if I don't run this thing by my own then what will happen maybe somebody's actually going to load the entire file at that time you guys might be going to get a new error and if I don't have the solution ready then probably it will be not good so that is why I'll be just going to run this uh thing till end I'll just try to load everything and after that I'll just going to upload the video along with the along with my findings the source code and the video I'm sorry the data file okay so I'll just going to conclude uh the video here for the time being and after that in the next session I'll be just going to show you guys the result of this query execution and the output from the ne forj graph right okay so so just stay tuned for the last part I'll be going to come back very soon okay all right so it's still running and as of now total uh 2.45k means 2.5k records are created in terms of notes right and probably okay almost 600,000 like relationships are created so basically you see like brand category order product user item so basically let's say let's item Philips there is a brand and if click here and it's still running okay so let's click on this thing uh like this so see like this okay so it's coming nicely okay right so maybe what we'll do uh okay return o limit one so let's try to actually get one order okay like this and what we'll do we'll just click on this thing okay so basically user placed an order order made for an product and this order is also made for this product so basically uh both of this product might belongs to a like what do you say like a brand so let's click on this thing so basically this is belongs to a uh what will be the brand maybe this is a brand okay so like this right so maybe um if you run this thing for longer duration it will be completed so okay so as I told you I'll try to actually run it uh for longer duration and if I'm going to get some error I'll try to explain this thing with you so first of all uh let me actually show you something uh don't wor I'll change this thing so basically password so basically I change the query a little bit so Marge is actually like this whatever was there but I just uh okay sorry I just uh change the uh change this part a little bit like earlier it was like together right now I just break this thing into separate like uh uh step so basically this will make sure that nothing is actually duplicated okay that is one thing uh second thing is actually uh okay obviously you understand this is not my uh Neo 4J like sandbox URL this is kind of an aura new 4J Aura from uh Cloud actually so basically this is my for instance because uh if you are trying to load like let's say 3 million record and if you're going to run it from the ne4 sandbox sandbox will be actually a little bit slow after some time so that is why to avoid this thing I'm actually doing uh because why it is going to be slow because in new 4G sandbox the memory size and other things are limited so basically to uh fine tune your performance you have to use highly efficient machine I believe for that purpose I actually tried to use Aura and that actually give me an idea like how much cost you have to bear so basically it is running uh for almost 4 hour let me check how much hour it is running so almost 4 hour right so in 4 hours how many node I loaded so let me check here so in 4 hours I have almost loaded 2.49k nodes and 6.18 K 600 almost 620,000 relationships and 250 uh, actually 250 uh uh th000 uh like uh nodes right so 4 hours and the cost of 4 hour is actually if I just go here uh yes here it is almost $15 now next thing you cannot actually run this thing from your databas datab break Community notebook because they have a limitation after 60 Minute it will be automatically terminated because it's a free version so because of that I have to again use an Azure notebook uh and this is actually running from my Azure like data break so basically first of all you have to create an azure your portal account and after that you have to search for datab break service you have to then launch your datab breaks workspace and after that you can create the notebook so what I'll do I'll just try to share the uh notebook with you guys and also the like source code so there is not much error no error other than this small small Performance Tuning kind of a thing so for that reason it is better to actually try this thing with NE 4G AA with any uh paid or Enterprise data briak cluster so basically again it's some sort of cost is involved with this thing just because I'm just making this tutorial for all of you so it's not a problem but um uh with that note I'll just going to ask you guys something please do me a favor U by try to uh subscribe to my channel and hit the like button if you really enjoy my videos so after watching my videos if you feel these videos can be like U ra to the larger audience then also try to share the videos with your family and friends okay this is the small H I'm actually look looking forward from all of you guys because you can see for this video I actually invest some of my time and some of my money as well right okay so what I'll do now I'll be just going to terminate the instance CU you can calculate this things so I have a 3 million record okay so basically how many records are created now so 2.51 right 2.5k so basically 10 times so basically uh whatever is we created so not 10 times 2.5k so actually 2 million record we have actually almost 2.5k million records are there so basically 250k is created so basically um still it will be almost uh 10 times right so basically you have to run the notebook for almost 40 hours right so basically what you can do uh that you can try just try to actually increase the B size to 10,000 and try to do it whether the performance improves or not that I can actually uh uh I want to actually give you guys kind of an assignment and try to do it and let me know okay okay so that's it this is your end to end data injection using a CSV file uh using U spark connector and that to from uh data breaks okay so I'll be going to conclude the video here and before I conclude guys again one more time it's a humble request please try to subscribe to our Channel if somebody's watching my video for the first time please please do subscribe to our Channel hit the Bell notification so you should not miss any notification from the future and also if you enjoy my work and also you like my videos please try to share our videos with your family and friend and also uh put some comment by by uh comment box and let me know whether these things are helping you on some of your work or if you think something could be done in a better way just let me know I'll try to actually improve our quality in our upcoming videos okay with that note this video is actually um I expected that this could be done in 1 hour but it is uh more than this thing so I'd like to conclude the video over here see you in the next video till then take care goodbye have a nice day and happy learning